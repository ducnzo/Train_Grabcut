{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.applications.efficientnet import preprocess_input, EfficientNetB5, EfficientNetB4\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications import MobileNetV3Large, MobileNetV3Small\n",
    "from keras.applications.efficientnet_v2 import EfficientNetV2B0, EfficientNetV2B1, EfficientNetV2B2, EfficientNetV2B3, EfficientNetV2S, EfficientNetV2M, EfficientNetV2L\n",
    "\n",
    "# Tạo model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# Tạo và xử lý data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Hàm loss và optimizer\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Callbacks\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tabulate import tabulate\n",
    "# ROC Curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "#Checkpoint and log\n",
    "from keras.callbacks import CSVLogger\n",
    "import tempfile\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "\n",
    "#Time inference\n",
    "import cv2\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Ranger\n",
    "\n",
    "import tensorflow_addons as tfa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xây dựng mô hình\n",
    "num_classes = 4\n",
    "IMG_SIZE = 380\n",
    "batch_size = 8\n",
    "epochs = 50\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model = tf.keras.applications.efficientnet.EfficientNetB4(weights=None, include_top=True, classes=num_classes) \n",
    "predictions = base_model(inputs)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# Đóng băng các lớp của mô hình base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn đến thư mục chứa dữ liệu\n",
    "data_dir = '/home/ducna/Coding/Data/Data_Grabcut_Use_Augmented/train'\n",
    "test_dir = '/home/ducna/Coding/Data/Data_Grabcut_Use_Augmented/test'\n",
    "# Thiết lập các thông số\n",
    "validation_ratio = 0.1\n",
    "\n",
    "# Sử dụng ImageDataGenerator để tạo dữ liệu và áp dụng các biến đổi\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=validation_ratio,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Tạo generator cho tập train và tập validation\n",
    "train_data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Chỉ sử dụng tập huấn luyện\n",
    ")\n",
    "\n",
    "val_data_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Chỉ sử dụng tập validation\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1 / 255.0)\n",
    "test_data_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save log\n",
    "class TimeTrainCSVLogger(tf.keras.callbacks.CSVLogger):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "        super().on_epoch_begin(epoch, logs)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_duration = epoch_end_time - self.epoch_start_time\n",
    "        logs['time_per_epoch'] = epoch_duration\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "        print(f\"Epoch {epoch + 1} - Training Time: {epoch_duration:.2f} seconds\")\n",
    "        \n",
    "class TrainingTimeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.start_time = time.time()\n",
    "        super().on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        end_time = time.time()\n",
    "        duration = end_time - self.start_time\n",
    "        super().on_train_end(logs)\n",
    "        hours = duration // 3600\n",
    "        minutes = (duration - (hours * 3600)) // 60\n",
    "        seconds = duration - ((hours * 3600) + (minutes * 60))\n",
    "        \n",
    "        msg = f'Total Training Time: {int(hours)} hours, {int(minutes)} minutes, {seconds:.2f} seconds'\n",
    "        print(msg)\n",
    "\n",
    "        # Ghi tổng thời gian huấn luyện vào tệp CSV\n",
    "        with open('train_logger2.csv', mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Total Training Time (seconds)'])\n",
    "            writer.writerow([duration])\n",
    "            writer.writerow(['Total Training Time (hours, minutes, seconds)'])\n",
    "            writer.writerow([hours, minutes, seconds])\n",
    "\n",
    "csv_logger = TimeTrainCSVLogger('train_logger.csv', append=True, separator='\\t')\n",
    "\n",
    "checkpoint_filepath = \"cp.ckpt\"\n",
    "directory_checkpoint = os.path.dirname(checkpoint_filepath)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    verbose=2,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss = CategoricalCrossentropy()\n",
    "\n",
    "#Optimizer Ranger\n",
    "radam = tfa.optimizers.RectifiedAdam(learning_rate=1e-3)\n",
    "ranger = tfa.optimizers.Lookahead(radam, sync_period=6, slow_step_size=0.5)\n",
    "# optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "model.compile(loss=loss, optimizer=ranger, metrics= ['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])\n",
    "\n",
    "# Tính toán số bước cho tập train và tập validation\n",
    "steps_per_epoch = train_data_generator.samples // batch_size\n",
    "validation_steps = val_data_generator.samples // batch_size\n",
    "\n",
    "history = model.fit(train_data_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          validation_steps= validation_steps, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          validation_data=val_data_generator, \n",
    "          callbacks=[model_checkpoint_callback,csv_logger,TrainingTimeCallback()]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá mô hình trên tệp test\n",
    "test_loss, test_accuracy, test_recall, test_precision = model.evaluate(test_data_generator)\n",
    "\n",
    "print(f'Test_loss: {test_loss}')\n",
    "print(f'Test_accuracy: {test_accuracy}')\n",
    "print(f'Test_recall: {test_recall}')\n",
    "print(f'Test_precision: {test_precision}')\n",
    "\n",
    "with open('Test_data_metrics.txt', 'w') as file:\n",
    "    file.write(f'Test_loss: {test_loss}\\n')\n",
    "    file.write(f'Test_accuracy: {test_accuracy}\\n')\n",
    "    file.write(f'Test_recall: {test_recall}\\n')\n",
    "    file.write(f'Test_precision: {test_precision}\\n')\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save('B4_Ranger.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy thông tin về độ chính xác trên tập huấn luyện và tập validation\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của accuracy\n",
    "plt.plot(range(1, epochs + 1), train_accuracy, label='Training Accuracy')\n",
    "plt.plot(range(1, epochs + 1), val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_vs_epochs.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Lấy thông tin về loss trên tập huấn luyện và tập validation\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Vẽ đồ thị biểu diễn sự thay đổi của loss\n",
    "plt.plot(range(1, epochs + 1), train_loss, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('loss_vs_epochs.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'precision' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precision vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('precision_vs_epochs.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('recall_vs_epochs.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Extract available metrics keys from the training history\n",
    "metric_keys = [key for key in history.history.keys() if 'recall' in key]\n",
    "\n",
    "# Plot the available recall metrics with modified labels\n",
    "epochs_range = range(1, len(history.history[metric_keys[0]]) + 1)\n",
    "\n",
    "# Extract the modified labels without \"_1\" and capitalize them\n",
    "labels = [key.replace('_1', '').capitalize() for key in metric_keys]\n",
    "\n",
    "# Plot all recall metrics in one go with modified labels\n",
    "for key, label in zip(metric_keys, labels):\n",
    "    plt.plot(epochs_range, history.history[key], label=label)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall vs Epochs')\n",
    "plt.legend()\n",
    "plt.savefig('recall_vs_epochs.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Dự đoán trên tập kiểm tra và lấy nhãn dự đoán\n",
    "y_pred = model.predict(test_data_generator)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Lấy nhãn thật của tập kiểm tra\n",
    "y_true_indices = test_data_generator.classes\n",
    "\n",
    "# Lấy danh sách các lớp từ tên thư mục trong val_data_generator\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "\n",
    "# Sử dụng chỉ số thứ tự để lấy tên của các lớp từ danh sách tên lớp\n",
    "y_true_classes = [class_names[i] for i in y_true_indices]\n",
    "\n",
    "# Tính toán confusion matrix\n",
    "cm = confusion_matrix(y_true_indices, y_pred_labels)\n",
    "\n",
    "# Hiển thị confusion matrix bằng heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png') # save before show. If not, it will save a blank image\n",
    "plt.show()\n",
    "\n",
    "# Tính classification report\n",
    "class_names = list(test_data_generator.class_indices.keys())\n",
    "report = classification_report(y_true_indices, y_pred_labels, target_names=class_names, output_dict=True)\n",
    "\n",
    "# Tạo bảng classification report\n",
    "report_table = []\n",
    "for class_name, metrics in report.items():\n",
    "    if class_name in class_names:\n",
    "        row = [class_name, metrics['precision'], metrics['recall'], metrics['f1-score']]\n",
    "        report_table.append(row)\n",
    "\n",
    "headers = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "report_text = tabulate(report_table, headers, tablefmt=\"pretty\")\n",
    "# Lưu bảng classification report vào tệp văn bản\n",
    "with open('classification_report.txt', 'w') as file:\n",
    "    file.write(report_text)\n",
    "\n",
    "# In bảng classification report ra màn hình\n",
    "print(report_text)\n",
    "\n",
    "# Chuyển đổi nhãn thành định dạng mã hóa one-hot\n",
    "y_test_binary = label_binarize(test_data_generator.labels, classes=range(len(class_names)))\n",
    "\n",
    "# Khởi tạo một từ điển trống để lưu FPR và TPR cho mỗi lớp\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "# Tạo một hình ảnh cho các đường ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Duyệt qua từng lớp\n",
    "for i in range(len(class_names)):\n",
    "    # Tính toán đường ROC và AUC cho lớp hiện tại\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binary[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Vẽ đường ROC cho lớp hiện tại\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve for {class_names[i]} (area = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Cài đặt plot\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('ROC_curve.png') # save before show. If not, it will save a blank image\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
